{
  "components": {
    "comp-deploy-fastapi-predictor": {
      "executorLabel": "exec-deploy-fastapi-predictor",
      "inputDefinitions": {
        "parameters": {
          "docker_folder": {
            "parameterType": "STRING"
          },
          "gcp_credentials_json": {
            "parameterType": "STRING"
          },
          "gcr_image": {
            "parameterType": "STRING"
          },
          "gcs_bucket": {
            "parameterType": "STRING"
          },
          "model_prefix": {
            "defaultValue": "results",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "project_id": {
            "parameterType": "STRING"
          },
          "region": {
            "parameterType": "STRING"
          },
          "service_name": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "Output": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-extract-matrix-component": {
      "executorLabel": "exec-extract-matrix-component",
      "inputDefinitions": {
        "parameters": {
          "database_url": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "matrix_output": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "metadata_output": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-model-component": {
      "executorLabel": "exec-train-model-component",
      "inputDefinitions": {
        "artifacts": {
          "matrix_input": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "metadata_input": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "batch_size": {
            "defaultValue": 64.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "epochs": {
            "defaultValue": 30.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model_output": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-upload-model-component": {
      "executorLabel": "exec-upload-model-component",
      "inputDefinitions": {
        "artifacts": {
          "model_path": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "gcp_credentials_json": {
            "parameterType": "STRING"
          },
          "output_dir": {
            "parameterType": "STRING"
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-deploy-fastapi-predictor": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "deploy_fastapi_predictor"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-storage' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef deploy_fastapi_predictor(\n    gcp_credentials_json: str,\n    project_id: str,\n    region: str,\n    service_name: str,\n    docker_folder: str,\n    gcr_image: str,\n    gcs_bucket: str,\n    model_prefix: str = \"results\"\n) -> str:\n    import os\n    import subprocess\n    import shutil\n    from google.cloud import storage\n\n    os.makedirs(\"/tmp/gcp\", exist_ok=True)\n    cred_path = \"/tmp/gcp/credentials.json\"\n    with open(cred_path, \"w\") as f:\n        f.write(gcp_credentials_json)\n\n    subprocess.run([\n        \"gcloud\", \"auth\", \"activate-service-account\", \"--key-file\", cred_path\n    ], check=True)\n\n    subprocess.run([\n        \"gcloud\", \"config\", \"set\", \"project\", project_id\n    ], check=True)\n\n    model_dir = os.path.join(docker_folder, \"model\")\n    os.makedirs(model_dir, exist_ok=True)\n\n    storage_client = storage.Client.from_service_account_json(cred_path)\n    bucket = storage_client.bucket(gcs_bucket)\n\n    model_blob = bucket.blob(f\"{model_prefix}/recvae_model.pt\")\n    meta_blob = bucket.blob(f\"{model_prefix}/recvae_metadata.pkl\")\n\n    model_blob.download_to_filename(os.path.join(model_dir, \"recvae_model.pt\"))\n    meta_blob.download_to_filename(os.path.join(model_dir, \"recvae_metadata.pkl\"))\n\n    template_dir = os.path.join(os.path.dirname(__file__), \"fastapi_template\")\n    for filename in [\"inference.py\", \"recvae_model.py\", \"requirements.txt\", \"Dockerfile\"]:\n        shutil.copy(os.path.join(template_dir, filename), os.path.join(docker_folder, filename))\n\n    os.chdir(docker_folder)\n\n    subprocess.run([\n        \"gcloud\", \"builds\", \"submit\",\n        \"--tag\", gcr_image,\n        \"--project\", project_id\n    ], check=True)\n\n    subprocess.run([\n        \"gcloud\", \"run\", \"deploy\", service_name,\n        \"--image\", gcr_image,\n        \"--region\", region,\n        \"--platform\", \"managed\",\n        \"--allow-unauthenticated\",\n        \"--project\", project_id\n    ], check=True)\n\n    service_url = f\"https://{service_name}-{region}.a.run.app\"\n    print(\"\u2705 Cloud Run service deployed:\", service_url)\n    return service_url\n\n"
          ],
          "image": "gcr.io/cloud-builders/gcloud"
        }
      },
      "exec-extract-matrix-component": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "extract_matrix_component"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'sqlalchemy' 'numpy' 'psycopg2-binary' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef extract_matrix_component(\n    database_url: str,\n    matrix_output: Output[Dataset],\n    metadata_output: Output[Dataset]\n):\n    import numpy as np\n    import pickle\n    import os\n    from sqlalchemy import create_engine\n    from sqlalchemy.orm import sessionmaker, relationship, declarative_base\n    from sqlalchemy import Column, Integer, String, ForeignKey, Table, Boolean, BigInteger\n\n    Base = declarative_base()\n\n    user_likes = Table(\n        'user_likes', Base.metadata,\n        Column('username', String, ForeignKey('users.username'), primary_key=True),\n        Column('song_id', Integer, ForeignKey('tracks.id'), primary_key=True)\n    )\n\n    class User(Base):\n        __tablename__ = 'users'\n        id = Column(Integer, primary_key=True, autoincrement=True)\n        username = Column(String, unique=True, nullable=False)\n        liked_songs = relationship('Track', secondary=user_likes, back_populates='liked_by')\n\n    class Artist(Base):\n        __tablename__ = 'artists'\n        id = Column(Integer, primary_key=True, autoincrement=True)\n        name = Column(String, nullable=False)\n\n    class Track(Base):\n        __tablename__ = 'tracks'\n        id = Column(BigInteger, primary_key=True, autoincrement=False)\n        title = Column(String, nullable=False)\n        link = Column(String)\n        duration = Column(BigInteger)\n        preview = Column(String)\n        position = Column(BigInteger)\n        rank = Column(BigInteger)\n        explicit_lyrics = Column(Boolean)\n        album_id = Column(BigInteger)\n        album_title = Column(String)\n        album_cover = Column(String)\n        artist_id = Column(BigInteger, ForeignKey('artists.id'))\n        liked_by = relationship('User', secondary=user_likes, back_populates='liked_songs')\n\n    engine = create_engine(database_url)\n    SessionLocal = sessionmaker(bind=engine)\n    session = SessionLocal()\n\n    users = session.query(User).all()\n    tracks = session.query(Track).all()\n\n    user_ids = [user.username for user in users]\n    track_ids = [track.id for track in tracks]\n\n    user_idx = {u: i for i, u in enumerate(user_ids)}\n    track_idx = {t: i for i, t in enumerate(track_ids)}\n\n    matrix = np.zeros((len(users), len(tracks)), dtype=np.float32)\n    for user in users:\n        for track in user.liked_songs:\n            if track.id in track_idx:\n                matrix[user_idx[user.username], track_idx[track.id]] = 1.0\n\n    os.makedirs(matrix_output.path, exist_ok=True)\n    os.makedirs(metadata_output.path, exist_ok=True)\n\n    np.save(os.path.join(matrix_output.path, \"matrix.npy\"), matrix)\n    with open(os.path.join(metadata_output.path, \"meta.pkl\"), \"wb\") as f:\n        pickle.dump({\"user_ids\": user_ids, \"track_ids\": track_ids}, f)\n\n    session.close()\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-train-model-component": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_model_component"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'torch' 'numpy' 'pickle5' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_model_component(\n    matrix_input: Input[Dataset],\n    metadata_input: Input[Dataset],\n    model_output: Output[Model],\n    epochs: int = 30,\n    batch_size: int = 64\n):\n    import numpy as np\n    import pickle\n    import os\n    import torch\n    import torch.nn as nn\n    import torch.nn.functional as F\n\n    os.makedirs(model_output.path, exist_ok=True)\n\n    class RecVAE(nn.Module):\n        def __init__(self, input_dim, hidden_dim=600, latent_dim=200, dropout=0.5):\n            super(RecVAE, self).__init__()\n            self.encoder = nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.Tanh(),\n                nn.Dropout(dropout),\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.Tanh(),\n                nn.Dropout(dropout)\n            )\n            self.mu_layer = nn.Linear(hidden_dim, latent_dim)\n            self.logvar_layer = nn.Linear(hidden_dim, latent_dim)\n            self.decoder = nn.Sequential(\n                nn.Linear(latent_dim, hidden_dim),\n                nn.Tanh(),\n                nn.Dropout(dropout),\n                nn.Linear(hidden_dim, input_dim),\n            )\n\n        def reparameterize(self, mu, logvar):\n            std = torch.exp(0.5 * logvar)\n            eps = torch.randn_like(std)\n            return mu + eps * std\n\n        def forward(self, x):\n            encoded = self.encoder(x)\n            mu = self.mu_layer(encoded)\n            logvar = self.logvar_layer(encoded)\n            z = self.reparameterize(mu, logvar)\n            decoded = self.decoder(z)\n            return decoded, mu, logvar\n\n        def loss_fn(self, recon_x, x, mu, logvar):\n            BCE = F.binary_cross_entropy_with_logits(recon_x, x, reduction='sum')\n            KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n            return BCE + KLD\n\n    matrix = np.load(os.path.join(matrix_input.path, \"matrix.npy\"))\n    with open(os.path.join(metadata_input.path, \"meta.pkl\"), \"rb\") as f:\n        meta = pickle.load(f)\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    input_dim = matrix.shape[1]\n    model = RecVAE(input_dim).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    dataset = torch.utils.data.TensorDataset(torch.tensor(matrix, dtype=torch.float32))\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for batch in dataloader:\n            x_batch = batch[0].to(device)\n            optimizer.zero_grad()\n            recon_x, mu, logvar = model(x_batch)\n            loss = model.loss_fn(recon_x, x_batch, mu, logvar)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.2f}\")\n\n    torch.save(model.state_dict(), os.path.join(model_output.path, \"recvae_model.pt\"))\n    with open(os.path.join(model_output.path, \"recvae_metadata.pkl\"), \"wb\") as f:\n        pickle.dump(meta, f)\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-upload-model-component": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "upload_model_component"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-storage' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef upload_model_component(\n    model_path: Input[Model],\n    gcp_credentials_json: str,\n    output_dir: str\n):\n    import os\n    from google.cloud import storage\n\n    credentials_path = \"/tmp/gcp_credentials.json\"\n    with open(credentials_path, \"w\") as f:\n        f.write(gcp_credentials_json)\n    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n\n    client = storage.Client()\n    bucket_name = output_dir.replace(\"gs://\", \"\").split(\"/\")[0]\n    prefix = \"/\".join(output_dir.replace(\"gs://\", \"\").split(\"/\")[1:])\n    bucket = client.bucket(bucket_name)\n    bucket.blob(f\"{prefix}/recvae_model.pt\").upload_from_filename(os.path.join(model_path.path, \"recvae_model.pt\"))\n    bucket.blob(f\"{prefix}/recvae_metadata.pkl\").upload_from_filename(os.path.join(model_path.path, \"recvae_metadata.pkl\"))\n\n"
          ],
          "image": "python:3.10"
        }
      }
    }
  },
  "pipelineInfo": {
    "name": "recvae-training-pipeline"
  },
  "root": {
    "dag": {
      "tasks": {
        "deploy-fastapi-predictor": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-deploy-fastapi-predictor"
          },
          "dependentTasks": [
            "upload-model-component"
          ],
          "inputs": {
            "parameters": {
              "docker_folder": {
                "componentInputParameter": "docker_folder"
              },
              "gcp_credentials_json": {
                "componentInputParameter": "gcp_credentials_json"
              },
              "gcr_image": {
                "componentInputParameter": "gcr_image"
              },
              "gcs_bucket": {
                "componentInputParameter": "output_dir"
              },
              "model_prefix": {
                "componentInputParameter": "model_prefix"
              },
              "project_id": {
                "componentInputParameter": "project_id"
              },
              "region": {
                "componentInputParameter": "region"
              },
              "service_name": {
                "componentInputParameter": "service_name"
              }
            }
          },
          "taskInfo": {
            "name": "deploy-fastapi-predictor"
          }
        },
        "extract-matrix-component": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-extract-matrix-component"
          },
          "inputs": {
            "parameters": {
              "database_url": {
                "componentInputParameter": "database_url"
              }
            }
          },
          "taskInfo": {
            "name": "extract-matrix-component"
          }
        },
        "train-model-component": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-model-component"
          },
          "dependentTasks": [
            "extract-matrix-component"
          ],
          "inputs": {
            "artifacts": {
              "matrix_input": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "matrix_output",
                  "producerTask": "extract-matrix-component"
                }
              },
              "metadata_input": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "metadata_output",
                  "producerTask": "extract-matrix-component"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-model-component"
          }
        },
        "upload-model-component": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-upload-model-component"
          },
          "dependentTasks": [
            "train-model-component"
          ],
          "inputs": {
            "artifacts": {
              "model_path": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model_output",
                  "producerTask": "train-model-component"
                }
              }
            },
            "parameters": {
              "gcp_credentials_json": {
                "componentInputParameter": "gcp_credentials_json"
              },
              "output_dir": {
                "componentInputParameter": "output_dir"
              }
            }
          },
          "taskInfo": {
            "name": "upload-model-component"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "database_url": {
          "parameterType": "STRING"
        },
        "docker_folder": {
          "parameterType": "STRING"
        },
        "gcp_credentials_json": {
          "parameterType": "STRING"
        },
        "gcr_image": {
          "parameterType": "STRING"
        },
        "model_prefix": {
          "defaultValue": "results",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "output_dir": {
          "parameterType": "STRING"
        },
        "project_id": {
          "parameterType": "STRING"
        },
        "region": {
          "parameterType": "STRING"
        },
        "service_name": {
          "parameterType": "STRING"
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.12.1"
}